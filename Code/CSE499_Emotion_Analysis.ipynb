{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE499 Emotion Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erfan-Mostafiz/CSE499_Emotion-Analysis/blob/Erfan/Code/CSE499_Emotion_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LdeqFKH7LAy",
        "outputId": "39b0269e-17bd-4653-9374-66e07d188ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/CSE499_EmotionAnalysis/DeepVANet-main.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6I7h6Ew9aqb",
        "outputId": "98570fbd-d20a-47da-9500-560ff04c688c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/CSE499_EmotionAnalysis/DeepVANet-main.zip\n",
            "   creating: DeepVANet-main/\n",
            "  inflating: DeepVANet-main/dataset.py  \n",
            "  inflating: DeepVANet-main/data_preprocess.py  \n",
            "  inflating: DeepVANet-main/decision_level_fusion.py  \n",
            "  inflating: DeepVANet-main/demo.py  \n",
            "  inflating: DeepVANet-main/models.py  \n",
            "  inflating: DeepVANet-main/pretrained_cnn.pth  \n",
            "  inflating: DeepVANet-main/readme.md  \n",
            "  inflating: DeepVANet-main/train.py  \n",
            "  inflating: DeepVANet-main/utils.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/CSE499_EmotionAnalysis/Reduced/datasets.zip\""
      ],
      "metadata": {
        "id": "X0VwVThxLZZ3",
        "outputId": "681ce492-70b5-4a91-cc02-1cda2a836bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/CSE499_EmotionAnalysis/Reduced/datasets.zip\n",
            "   creating: datasets/\n",
            "   creating: datasets/DEAP/\n",
            "   creating: datasets/DEAP/data_preprocessed_python/\n",
            "   creating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/\n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s01.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s02.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s03.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s04.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s05.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s06.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s07.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s08.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s09.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s10.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s11.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s12.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s13.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s14.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s15.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s16.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s17.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s18.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s19.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s20.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s21.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s22.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s23.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s24.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s25.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s26.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s27.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s28.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s29.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s30.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s31.dat  \n",
            "  inflating: datasets/DEAP/data_preprocessed_python/data_preprocessed_python/s32.dat  \n",
            "  inflating: datasets/DEAP/DEAP.pdf  \n",
            "   creating: datasets/DEAP/face_video/\n",
            "   creating: datasets/DEAP/face_video/s01/\n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s01/s01_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s02/\n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s02/s02_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s03/\n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s03/s03_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s04/\n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s04/s04_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s05/\n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s05/s05_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s06/\n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s06/s06_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s07/\n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s07/s07_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s08/\n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s08/s08_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s09/\n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s09/s09_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s10/\n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s10/s10_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s11/\n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s11/s11_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s12/\n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s12/s12_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s13/\n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s13/s13_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s14/\n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s14/s14_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s15/\n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s15/s15_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s16/\n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s16/s16_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s17/\n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s17/s17_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s18/\n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s18/s18_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s19/\n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s19/s19_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s20/\n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s20/s20_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s21/\n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s21/s21_trial10.avi  \n",
            "   creating: datasets/DEAP/face_video/s22/\n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial01.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial02.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial03.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial04.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial05.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial06.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial07.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial08.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial09.avi  \n",
            "  inflating: datasets/DEAP/face_video/s22/s22_trial10.avi  \n",
            "   creating: datasets/DEAP/metadata_csv/\n",
            "  inflating: datasets/DEAP/metadata_csv/online_ratings.csv  \n",
            "  inflating: datasets/DEAP/metadata_csv/participant_questionnaire.csv  \n",
            "  inflating: datasets/DEAP/metadata_csv/participant_ratings.csv  \n",
            "  inflating: datasets/DEAP/metadata_csv/video_list.csv  \n",
            "   creating: datasets/DEAP/metadata_xls/\n",
            "  inflating: datasets/DEAP/metadata_xls/online_ratings.xls  \n",
            "  inflating: datasets/DEAP/metadata_xls/participant_questionnaire.xls  \n",
            "  inflating: datasets/DEAP/metadata_xls/participant_ratings.xls  \n",
            "  inflating: datasets/DEAP/metadata_xls/video_list.xls  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchvision import transforms as T\n",
        "import io\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "5oJHSerJ7r1e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DEAP(data.Dataset):\n",
        "    '''\n",
        "    DEAP dataset for per-subject experiments\n",
        "    Parameters:\n",
        "        modal   : data modality; {'face', 'eeg', 'peri', 'bio', 'faceeeg', 'faceperi', 'facebio'}, default = 'facebio'.\n",
        "        subject : subject ID; an integer between 1 and 22, default = 1.\n",
        "        k       : kth fold; an integer between 1 and 10, default = 1.\n",
        "        kind    : dataset type; {'train', 'val', 'all'}, default = 'all'.\n",
        "        indices : index of data samples (for dataset shuffle); an list of integers, default = list(range(2400)).\n",
        "        label   : emotion label; {'valence', 'arousal'}, defualt = 'valence'.\n",
        "    '''\n",
        "    def __init__(self, modal='facebio', subject=1, k=1, kind='all', indices=list(range(2400)),label='valence'):\n",
        "        self.modal = modal\n",
        "        self.subject = subject\n",
        "        self.k = k\n",
        "        self.kind = kind\n",
        "        self.label = label\n",
        "        self.bio_path = f'./data/DEAP/bio/s{subject}.zip'\n",
        "        self.label_path = f'./data/DEAP/labels/'\n",
        "        self.face_path = f'./data/DEAP/faces/s{subject}.zip'\n",
        "        self.labels = pd.read_csv(self.label_path+'participant_ratings.csv')\n",
        "        self.face_zip = zipfile.ZipFile(self.face_path, 'r')\n",
        "        self.bio_zip = zipfile.ZipFile(self.bio_path, 'r')\n",
        "        self.size = len(indices)\n",
        "\n",
        "        if kind == 'train':\n",
        "            self.indices = indices[:int((k - 1) * self.size / 10)] + indices[int(k * self.size / 10):]\n",
        "        if kind == 'val':\n",
        "            self.indices = indices[int((k - 1) * self.size / 10):int(k * self.size / 10)]\n",
        "        if kind == 'all':\n",
        "            self.indices = indices\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        index = self.indices[i]\n",
        "        trial = index // 60 + 1\n",
        "        segment = index % 60 + 1\n",
        "        prex = 's' + (str(self.subject) if self.subject > 9 else '0' + str(self.subject)) + '/s' + (\n",
        "            str(self.subject) if self.subject > 9 else '0' + str(self.subject)) + '_trial' + (\n",
        "                   str(trial) if trial > 9 else '0' + str(trial)) + '/s' + (\n",
        "                   str(self.subject) if self.subject > 9 else '0' + str(self.subject)) + '_trial' + (\n",
        "                   str(trial) if trial > 9 else '0' + str(trial))\n",
        "        transform = T.Compose([T.Resize((64, 64)),\n",
        "                               T.ToTensor()])\n",
        "\n",
        "        face_data = []\n",
        "        for n in range(1, 6):\n",
        "            img = Image.open(io.BytesIO(self.face_zip.read(prex + f'_{(segment - 1) * 5 + n}.png')))\n",
        "            frame_array = transform(img)\n",
        "            frame_array = frame_array.view(1, 3, 64, 64)\n",
        "            face_data.append(frame_array)\n",
        "        face_data = torch.cat(face_data, dim=0)\n",
        "        bio_data = torch.tensor(\n",
        "            np.load(io.BytesIO(self.bio_zip.read(f's{self.subject}/{self.subject}_{trial}_{segment}.npy')))).float()\n",
        "\n",
        "        if self.modal == 'face':\n",
        "            data = face_data\n",
        "        elif self.modal == 'eeg':\n",
        "            data = bio_data[:32]\n",
        "        elif self.modal == 'peri':\n",
        "            data = bio_data[32:]\n",
        "        elif self.modal == 'bio':\n",
        "            data = bio_data\n",
        "        elif self.modal == 'faceeeg':\n",
        "            data = (face_data, bio_data[:32])\n",
        "        elif self.modal == 'faceperi':\n",
        "            data = (face_data, bio_data[32:])\n",
        "        elif self.modal == 'facebio':\n",
        "            data = (face_data, bio_data)\n",
        "\n",
        "        valence = 0 if self.labels[(self.labels['Participant_id']==self.subject) & (self.labels['Trial']==trial)]['Valence'].iloc[0] < 5 else 1\n",
        "        arousal = 0 if self.labels[(self.labels['Participant_id']==self.subject) & (self.labels['Trial']==trial)]['Arousal'].iloc[0] < 5 else 1\n",
        "        if self.label == 'valence':\n",
        "            return data, valence\n",
        "        else:\n",
        "            return data, arousal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n"
      ],
      "metadata": {
        "id": "56AAq8Em0oLz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DEAPAll(data.Dataset):\n",
        "    def __init__(self, modal='facebio', k=1, kind='all', indices=list(range(52440)),label='valence'):\n",
        "        self.modal = modal\n",
        "        self.k = k\n",
        "        self.kind = kind\n",
        "        self.label = label\n",
        "        self.bio_path = f'./data/DEAP/bio/'\n",
        "        self.label_path = f'./data/DEAP/labels/'\n",
        "        self.face_path = f'./data/DEAP/faces/'\n",
        "        self.labels = pd.read_csv(self.label_path+'participant_ratings.csv')\n",
        "        deap_indices_dict = {1: 2400,\n",
        "                             2: 2400,\n",
        "                             3: 2340,\n",
        "                             4: 2400,\n",
        "                             5: 2340,\n",
        "                             6: 2400,\n",
        "                             7: 2400,\n",
        "                             8: 2400,\n",
        "                             9: 2400,\n",
        "                             10: 2400,\n",
        "                             11: 2220,\n",
        "                             12: 2400,\n",
        "                             13: 2400,\n",
        "                             14: 2340,\n",
        "                             15: 2400,\n",
        "                             16: 2400,\n",
        "                             17: 2400,\n",
        "                             18: 2400,\n",
        "                             19: 2400,\n",
        "                             20: 2400,\n",
        "                             21: 2400,\n",
        "                             22: 2400}\n",
        "        self.sub_trial_seg = []\n",
        "        for sub in range(1,23):\n",
        "            for trial in range(1,int(deap_indices_dict[sub]/60+1)):\n",
        "                for seg in range(1,61):\n",
        "                    self.sub_trial_seg.append((sub,trial,seg))\n",
        "        self.size = len(indices)\n",
        "\n",
        "        if kind == 'train':\n",
        "            self.indices = indices[:int((k - 1) * self.size / 10)] + indices[int(k * self.size / 10):]\n",
        "        if kind == 'val':\n",
        "            self.indices = indices[int((k - 1) * self.size / 10):int(k * self.size / 10)]\n",
        "        if kind == 'all':\n",
        "            self.indices = indices\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        index = self.indices[i]\n",
        "        subject, trial, segment = self.sub_trial_seg[index]\n",
        "        face_zip = zipfile.ZipFile(self.face_path+f's{subject}.zip', 'r')\n",
        "        bio_zip = zipfile.ZipFile(self.bio_path+f's{subject}.zip', 'r')\n",
        "        prex = 's' + (str(subject) if subject > 9 else '0' + str(subject)) + '/s' + (\n",
        "            str(subject) if subject > 9 else '0' + str(subject)) + '_trial' + (\n",
        "                   str(trial) if trial > 9 else '0' + str(trial)) + '/s' + (\n",
        "                   str(subject) if subject > 9 else '0' + str(subject)) + '_trial' + (\n",
        "                   str(trial) if trial > 9 else '0' + str(trial))\n",
        "        transform = T.Compose([T.Resize((64, 64)),\n",
        "                               T.ToTensor()])\n",
        "        face_data = []\n",
        "        for n in range(1, 6):\n",
        "            img = Image.open(io.BytesIO(face_zip.read(prex + f'_{(segment - 1) * 5 + n}.png')))\n",
        "            frame_array = transform(img)\n",
        "            frame_array = frame_array.view(1, 3, 64, 64)\n",
        "            face_data.append(frame_array)\n",
        "        face_data = torch.cat(face_data, dim=0)\n",
        "\n",
        "        bio_data = torch.tensor(np.load(io.BytesIO(bio_zip.read(f's{subject}/{subject}_{trial}_{segment}.npy')))).float()\n",
        "\n",
        "        if self.modal == 'face':\n",
        "            data = face_data\n",
        "        elif self.modal == 'eeg':\n",
        "            data = bio_data[:32]\n",
        "        elif self.modal == 'peri':\n",
        "            data = bio_data[32:]\n",
        "        elif self.modal == 'bio':\n",
        "            data = bio_data\n",
        "        elif self.modal == 'faceeeg':\n",
        "            data = (face_data, bio_data[:32])\n",
        "        elif self.modal == 'faceperi':\n",
        "            data = (face_data, bio_data[32:])\n",
        "        elif self.modal == 'facebio':\n",
        "            data = (face_data, bio_data)\n",
        "\n",
        "        valence = 0 if self.labels[(self.labels['Participant_id']==subject) & (self.labels['Trial']==trial)]['Valence'].iloc[0] < 5 else 1\n",
        "        arousal = 0 if self.labels[(self.labels['Participant_id']==subject) & (self.labels['Trial']==trial)]['Arousal'].iloc[0] < 5 else 1\n",
        "        if self.label == 'valence':\n",
        "            return data, valence\n",
        "        else:\n",
        "            return data, arousal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)"
      ],
      "metadata": {
        "id": "iW2hME810_DB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_alignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKXZMg3c29o1",
        "outputId": "1d8130f0-26ff-47bb-fd8a-35d57c294d9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_alignment\n",
            "  Downloading face_alignment-1.3.5.tar.gz (27 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from face_alignment) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_alignment) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from face_alignment) (1.7.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from face_alignment) (0.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from face_alignment) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from face_alignment) (4.64.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from face_alignment) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->face_alignment) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->face_alignment) (0.34.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face_alignment) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face_alignment) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face_alignment) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face_alignment) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face_alignment) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face_alignment) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment) (1.15.0)\n",
            "Building wheels for collected packages: face-alignment\n",
            "  Building wheel for face-alignment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-alignment: filename=face_alignment-1.3.5-py2.py3-none-any.whl size=28241 sha256=ca56f12171075a8dd63567f4663abb13ccc730b2db7706034e9a37ff275b1484\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/ba/4d/2d368f55e5f929f9472da59e356fbdf1483f885de80a5bc620\n",
            "Successfully built face-alignment\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyedflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz3yl1Ly3Oja",
        "outputId": "40be357e-57af-4f1e-acd0-bf594e79a989"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyedflib\n",
            "  Downloading pyEDFlib-0.1.30-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from pyedflib) (1.21.6)\n",
            "Installing collected packages: pyedflib\n",
            "Successfully installed pyedflib-0.1.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Functions for data pre-process\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import pickle as cPickle\n",
        "import os\n",
        "import face_alignment\n",
        "from xml.dom.minidom import parse\n",
        "import pyedflib\n",
        "import shutil"
      ],
      "metadata": {
        "id": "pYXggntH1H3I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ************************* Face Data Pre-process *************************\n",
        "\n",
        "def video2frames(dataset='DEAP'):\n",
        "    '''\n",
        "    Extract frames from videos.\n",
        "    :param dataset: used dataset\n",
        "    '''\n",
        "    assert dataset in ['DEAP', 'MAHNOB'], 'Invalid dataset name'\n",
        "\n",
        "    if dataset == 'DEAP':\n",
        "        dataset_path = './datasets/DEAP/face_video/'\n",
        "        des_path = './datasets/DEAP/frames/'\n",
        "        for subject in os.listdir(dataset_path):\n",
        "            if subject.startswith('.'):\n",
        "                continue\n",
        "            sub_path = dataset_path+subject\n",
        "            for video_file in os.listdir(sub_path):\n",
        "                if not os.path.exists(des_path + subject):\n",
        "                    os.mkdir(des_path + subject)\n",
        "                if not os.path.exists(des_path + subject + '/' + video_file.split('.')[0]):\n",
        "                    os.mkdir(des_path + subject + '/' + video_file.split('.')[0])\n",
        "                video_file_path = sub_path+'/'+video_file\n",
        "                video = cv2.VideoCapture(video_file_path)\n",
        "                c = 1\n",
        "                frame_rate = 10\n",
        "                count = 0\n",
        "                while (True):\n",
        "                    ret, frame = video.read()\n",
        "                    if ret:\n",
        "                        if (c % frame_rate == 0):\n",
        "                            count += 1\n",
        "                            cv2.imwrite(des_path+subject+'/'+video_file.split('.')[0] +'/'+ video_file.split('.')[0]+'_'+str(count) + '.png', frame)\n",
        "                        c += 1\n",
        "                        cv2.waitKey(0)\n",
        "                    else:\n",
        "                        break\n",
        "                video.release()\n"
      ],
      "metadata": {
        "id": "E0vJ4Vgf2W63"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions for face alignment and cropping are based on https://github.com/DANNALI35/zhihu_article/tree/master/201901_face_alignment\n",
        "def to_dict(landmarks):\n",
        "    '''\n",
        "    Transfer detected facial landmarks list to dictionary.\n",
        "    :param landmarks: a list of facial landmarks\n",
        "    :return: a dictionary of facial landmarks\n",
        "    '''\n",
        "    l = list()\n",
        "    for i in range(68):\n",
        "        point = (landmarks[i][0], landmarks[i][1])\n",
        "        l.append(point)\n",
        "    face_landmarks_dict = dict()\n",
        "    face_landmarks_dict['chin'] = l[0:17]\n",
        "    face_landmarks_dict['left_eyebrow'] = l[17:22]\n",
        "    face_landmarks_dict['right_eyebrow'] = l[22:27]\n",
        "    face_landmarks_dict['nose_bridge'] = l[27:31]\n",
        "    face_landmarks_dict['nose_tip'] = l[31:36]\n",
        "    face_landmarks_dict['left_eye'] = l[36:42]\n",
        "    face_landmarks_dict['right_eye'] = l[42:48]\n",
        "    face_landmarks_dict['top_lip'] = l[48:55] + l[60:65]\n",
        "    face_landmarks_dict['bottom_lip'] = l[55:60] + l[65:68]\n",
        "    return face_landmarks_dict\n",
        "\n",
        "\n",
        "def crop_face(image_array, landmarks):\n",
        "    \"\"\" crop face according to eye,mouth and chin position\n",
        "    :param image_array: numpy array of a single image\n",
        "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
        "    :return:\n",
        "    cropped_img: numpy array of cropped image\n",
        "    \"\"\"\n",
        "\n",
        "    eye_landmark = np.concatenate([np.array(landmarks['left_eye']),\n",
        "                                   np.array(landmarks['right_eye'])])\n",
        "    eye_center = np.mean(eye_landmark, axis=0).astype(\"int\")\n",
        "    lip_landmark = np.concatenate([np.array(landmarks['top_lip']),\n",
        "                                   np.array(landmarks['bottom_lip'])])\n",
        "    lip_center = np.mean(lip_landmark, axis=0).astype(\"int\")\n",
        "    mid_part = lip_center[1] - eye_center[1]\n",
        "    top = eye_center[1] - mid_part * 18 / 40\n",
        "    bottom = lip_center[1] + mid_part * 12 / 40\n",
        "\n",
        "    w = h = bottom - top\n",
        "    x_center = eye_center[0]\n",
        "    left, right = (x_center - w / 2, x_center + w / 2)\n",
        "\n",
        "    pil_img = Image.fromarray(image_array)\n",
        "    left, top, right, bottom = [int(i) for i in [left, top, right, bottom]]\n",
        "    cropped_img = pil_img.crop((left, top, right, bottom))\n",
        "    cropped_img = np.array(cropped_img)\n",
        "    return cropped_img, left, top"
      ],
      "metadata": {
        "id": "X3aQlX-Z3fjO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_landmarks(landmarks, eye_center, angle, row):\n",
        "    \"\"\" rotate landmarks to fit the aligned face\n",
        "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
        "    :param eye_center: tuple of coordinates for eye center\n",
        "    :param angle: degrees of rotation\n",
        "    :param row: row size of the image\n",
        "    :return: rotated_landmarks with the same structure with landmarks, but different values\n",
        "    \"\"\"\n",
        "    rotated_landmarks = defaultdict(list)\n",
        "    for facial_feature in landmarks.keys():\n",
        "        for landmark in landmarks[facial_feature]:\n",
        "            rotated_landmark = rotate(origin=eye_center, point=landmark, angle=angle, row=row)\n",
        "            rotated_landmarks[facial_feature].append(rotated_landmark)\n",
        "    return rotated_landmarks"
      ],
      "metadata": {
        "id": "EBeVvprv3mYC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate(origin, point, angle, row):\n",
        "    \"\"\" rotate coordinates in image coordinate system\n",
        "    :param origin: tuple of coordinates,the rotation center\n",
        "    :param point: tuple of coordinates, points to rotate\n",
        "    :param angle: degrees of rotation\n",
        "    :param row: row size of the image\n",
        "    :return: rotated coordinates of point\n",
        "    \"\"\"\n",
        "    x1, y1 = point\n",
        "    x2, y2 = origin\n",
        "    y1 = row - y1\n",
        "    y2 = row - y2\n",
        "    angle = math.radians(angle)\n",
        "    x = x2 + math.cos(angle) * (x1 - x2) - math.sin(angle) * (y1 - y2)\n",
        "    y = y2 + math.sin(angle) * (x1 - x2) + math.cos(angle) * (y1 - y2)\n",
        "    y = row - y\n",
        "    return int(x), int(y)"
      ],
      "metadata": {
        "id": "8SvgI4mY3p9X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_face(image_array, landmarks):\n",
        "    \"\"\" align faces according to eyes position\n",
        "    :param image_array: numpy array of a single image\n",
        "    :param landmarks: dict of landmarks for facial parts as keys and tuple of coordinates as values\n",
        "    :return:\n",
        "    rotated_img:  numpy array of aligned image\n",
        "    eye_center: tuple of coordinates for eye center\n",
        "    angle: degrees of rotation\n",
        "    \"\"\"\n",
        "    # get list landmarks of left and right eye\n",
        "    left_eye = landmarks['left_eye']\n",
        "    right_eye = landmarks['right_eye']\n",
        "    # calculate the mean point of landmarks of left and right eye\n",
        "    left_eye_center = np.mean(left_eye, axis=0).astype(\"int\")\n",
        "    right_eye_center = np.mean(right_eye, axis=0).astype(\"int\")\n",
        "    # compute the angle between the eye centroids\n",
        "    dy = right_eye_center[1] - left_eye_center[1]\n",
        "    dx = right_eye_center[0] - left_eye_center[0]\n",
        "    # compute angle between the line of 2 centeroids and the horizontal line\n",
        "    angle = math.atan2(dy, dx) * 180. / math.pi\n",
        "    # calculate the center of 2 eyes\n",
        "    eye_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
        "                  (left_eye_center[1] + right_eye_center[1]) // 2)\n",
        "    # at the eye_center, rotate the image by the angle\n",
        "    rotate_matrix = cv2.getRotationMatrix2D(eye_center, angle, scale=1)\n",
        "    rotated_img = cv2.warpAffine(image_array, rotate_matrix, (image_array.shape[1], image_array.shape[0]))\n",
        "    return rotated_img, eye_center, angle"
      ],
      "metadata": {
        "id": "4KsqrlsP3vLm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_landmarks(landmarks):\n",
        "    left_eye = landmarks['left_eye']\n",
        "    right_eye = landmarks['right_eye']\n",
        "    # calculate the mean point of landmarks of left and right eye\n",
        "    left_eye_center = np.mean(left_eye, axis=0).astype(\"int\")\n",
        "    right_eye_center = np.mean(right_eye, axis=0).astype(\"int\")\n",
        "    # compute the angle between the eye centroids\n",
        "    dy = right_eye_center[1] - left_eye_center[1]\n",
        "    dx = right_eye_center[0] - left_eye_center[0]\n",
        "    # compute angle between the line of 2 centeroids and the horizontal line\n",
        "    angle = math.atan2(dy, dx) * 180. / math.pi\n",
        "    # calculate the center of 2 eyes\n",
        "    eye_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
        "                  (left_eye_center[1] + right_eye_center[1]) // 2)\n",
        "#     rotated_landmarks = defaultdict(list)\n",
        "    rotated_landmarks = []\n",
        "    for facial_feature in landmarks.keys():\n",
        "        for landmark in landmarks[facial_feature]:\n",
        "            rotated_landmark = rotate(origin=eye_center, point=landmark, angle=angle, row=570)\n",
        "#             rotated_landmarks[facial_feature].append(rotated_landmark)\n",
        "            rotated_landmarks.append(rotated_landmark)\n",
        "    return rotated_landmarks"
      ],
      "metadata": {
        "id": "t_RGaarq32uM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_detection_alignment_cropping(dataset='DEAP'):\n",
        "    '''\n",
        "    Transfer frames to faces by face detection, alignment and cropping.\n",
        "    :param dataset: used dataset\n",
        "    '''\n",
        "    assert dataset in ['DEAP', 'MAHNOB'], 'Invalid dataset name'\n",
        "\n",
        "    # facial landmarks detector; use gpu by changing device parameter to 'cuda'\n",
        "    fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False, device='cpu')\n",
        "\n",
        "    if dataset == 'DEAP':\n",
        "        root = './datasets/DEAP/frames/'\n",
        "        des_path = './data/DEAP/faces/'\n",
        "\n",
        "    # if dataset == 'MAHNOB':\n",
        "    #     root = './datasets/MAHNOB/frames/'\n",
        "    #     des_path = './data/DEAP/faces/'\n",
        "\n",
        "    for subject in os.listdir(root):\n",
        "        for trial in os.listdir(root+subject):\n",
        "            if os.path.exists(des_path + subject + '/' + trial):\n",
        "                continue\n",
        "            os.mkdir(des_path + subject + '/' + trial)\n",
        "            for frame in os.listdir(root+subject+'/'+trial):\n",
        "                frame_path = root + subject + '/' + trial + '/' + frame\n",
        "                img = cv2.imread(frame_path)\n",
        "                preds = fa.get_landmarks(img)\n",
        "                try:\n",
        "                    landmarks_list = preds[0]\n",
        "                    landmarks_dict = to_dict(landmarks_list)\n",
        "                    aligned_face, eye_center, angle = align_face(image_array=img, landmarks=landmarks_dict)\n",
        "                    rotated_landmarks = rotate_landmarks(landmarks=landmarks_dict, eye_center=eye_center, angle=angle,\n",
        "                                                     row=img.shape[0])\n",
        "                    cropped_img, left, top = crop_face(image_array=aligned_face, landmarks=rotated_landmarks)\n",
        "\n",
        "                    cv2.imwrite(des_path + subject + '/' + trial + '/' + frame, cropped_img)\n",
        "                except:\n",
        "                    print(f'Fail to get the face image: {frame}')"
      ],
      "metadata": {
        "id": "kzUMtL6E3_lu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ************************* Bio-sensing Data Pre-process *************************\n",
        "\n",
        "def trial2segments(dataset='DEAP'):\n",
        "    '''\n",
        "    Divide bio-sensing data of each trial to 1-second length segments, and perform baseline removal.\n",
        "    Note, when dealing with MAHNOB-HCI dataset, EEG data should be common reference averaged, bandpass filtered and artefact removed using EEGLab,\n",
        "    and preprocessed EEG data files (one file per trial) should be stored in './datasets/MAHNOB/eeg_preprocessed/ folder in .npy format.\n",
        "    :param dataset: used dataset\n",
        "    '''\n",
        "    assert dataset in ['DEAP', 'MAHNOB'], 'Invalid dataset name'\n",
        "\n",
        "    if dataset == 'DEAP':\n",
        "        root = './datasets/DEAP/data_preprocessed_python/'\n",
        "        des_path = './data/DEAP/bio/'\n",
        "        labels = pd.read_csv('./data/DEAP/labels/participant_ratings.csv')\n",
        "        for file in os.listdir(root):\n",
        "            subject = file.split('.')[0]\n",
        "            sub_id = int(subject[1:])\n",
        "            os.mkdir(des_path + 's' + str(sub_id))\n",
        "            f = open(root + file, 'rb')\n",
        "            d = cPickle.load(f, encoding='latin1')\n",
        "            data = d['data']\n",
        "            for experiment in range(40):\n",
        "                trial = labels[(labels['Participant_id'] == sub_id) & (labels['Experiment_id'] == experiment + 1)][\n",
        "                    'Trial'].iloc[0]\n",
        "                # baseline\n",
        "                l = []\n",
        "                for i in range(3):\n",
        "                    l.append(data[experiment][:, i * 128:(i + 1) * 128])\n",
        "                baseline_mean = sum(l) / 3\n",
        "                # segments\n",
        "                for i in range(60):\n",
        "                    data_seg = data[experiment][:, 384 + i * 128:384 + (i + 1) * 128]\n",
        "                    data_seg_removed = data_seg - baseline_mean\n",
        "                    np.save(f'{des_path}s{sub_id}/{sub_id}_{trial}_{i + 1}.npy', data_seg_removed)"
      ],
      "metadata": {
        "id": "88s_dr4_4Iqh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_demo():\n",
        "    '''\n",
        "    This function pre-processes DEAP dataset.\n",
        "    Please unzip face_video.zip, data_preprocessed_python.zip and metadata_csv.zip from DEAP dataset in './datasets/DEAP/'.\n",
        "    Then call this function, the preprocessed data will be stored in './data/DEAP/'.\n",
        "    It is recommended to use a device with GPU, otherwise the face detection will be slow.\n",
        "    Note that faces cannot be detected from some frames, these frames should be replaced with the neighbour frame manually.\n",
        "    '''\n",
        "    # pre-process face data\n",
        "    if not os.path.exists('./datasets/DEAP/frames/'):\n",
        "        os.mkdir('./datasets/DEAP/frames/')\n",
        "    if not os.path.exists('./data/'):\n",
        "        os.mkdir('./data/')\n",
        "    if not os.path.exists('./data/DEAP/'):\n",
        "        os.mkdir('./data/DEAP/')\n",
        "    if not os.path.exists('./data/DEAP/faces/'):\n",
        "        os.mkdir('./data/DEAP/faces/')\n",
        "    if not os.path.exists('./data/DEAP/labels/'):\n",
        "        os.mkdir('./data/DEAP/labels/')\n",
        "    shutil.copy('./datasets/DEAP/metadata_csv/participant_ratings.csv', './data/DEAP/labels/participant_ratings.csv')\n",
        "    video2frames('DEAP')\n",
        "    face_detection_alignment_cropping('DEAP')\n",
        "\n",
        "    # preprocess bio-sensing data\n",
        "    if not os.path.exists('./data/DEAP/bio/'):\n",
        "        os.mkdir('./data/DEAP/bio/')\n",
        "    trial2segments('DEAP')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    preprocess_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "TtAgPZ0M4OLn",
        "outputId": "c8830ddd-9043-4c66-885c-0001f6dc63de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f4434eaa3f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mpreprocess_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-f4434eaa3f23>\u001b[0m in \u001b[0;36mpreprocess_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/DEAP/labels/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/DEAP/metadata_csv/participant_ratings.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data/DEAP/labels/participant_ratings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mvideo2frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEAP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mface_detection_alignment_cropping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEAP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8b4dae8ae185>\u001b[0m in \u001b[0;36mvideo2frames\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mframe_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "szbf06A87kYM"
      }
    }
  ]
}